# Configuration System Refactor - TODO

**Date Created:** 2025-10-10
**Date Completed:** 2025-10-17
**Status:** âœ… **COMPLETED** - All phases successfully implemented
**Priority:** HIGH
**Complexity:** Medium
**Estimated Effort:** 4-6 hours

---

## âœ… Completion Summary

This refactor has been **successfully completed**. All phases (1-4) were implemented:

- âœ… Phase 1: Removed `.env` model overrides, added `ProviderPreset` system
- âœ… Phase 2: Created `ModelInfo` class with unified naming, eliminated mapping functions
- âœ… Phase 3: (Deferred) Hot-reload can be added later if needed
- âœ… Phase 4: Documentation updated (README.md, PORT_ALLOCATION.md)

**Current State:** Provider switching now requires changing **ONE LINE** in `model_registry.py`:
```python
ACTIVE_PRESET = ProviderPreset.SAMBANOVA_FAST  # Line 198
```

All services automatically use the correct models from the active preset. No manual service coordination needed.

**Moving to archives:** This document is now historical reference material showing the design rationale and implementation plan.

---

## Problem Statement

### User Feedback
> "why changing all these takes so long we created shared service so that it should be easy.. but looks very complex.."

**User is absolutely right.** The shared model registry was designed to centralize model configuration and make changes simple, but the current implementation is overly complex and defeats the original design intent.

---

## Current State: What's Wrong

### What SHOULD Happen (Ideal Design)
1. Change model in **ONE place** (`shared/model_registry.py`)
2. All services automatically use the new model
3. No restarts needed (or minimal restarts with hot-reload)
4. Change takes < 30 seconds total

### What ACTUALLY Happens (Current Reality)
1. Edit `.env` file with new model names
2. Services don't see changes (they cache values at startup)
3. Manually restart 5+ services individually
4. Some services still use old cached values
5. Model names differ between providers (`Qwen3-32B` vs `Qwen/Qwen3-32B-fast`)
6. Need to write mapping functions to translate model name formats
7. Add provider detection logic
8. Update LLM Gateway routing rules
9. Change takes **15-30 minutes** with high error potential

---

## Root Causes

### 1. `.env` Overrides Defeat Centralization
**Location:** `shared/model_registry.py:29-30`

```python
# Problem: Loads .env ONCE at module import time, then cached!
env_path = Path(__file__).resolve().parents[1] / ".env"
load_dotenv(env_path)  # â† Runs when Python imports the module
```

**Impact:**
- Services cache `.env` values when they start
- Changing `.env` requires restarting ALL services
- The "shared registry" becomes just a passthrough to `.env`
- Defeats the purpose of having centralized model definitions

### 2. Multiple Model Name Formats
**Location:** `shared/model_registry.py:36-79`

```python
# Nebius format (with provider prefix and slash):
QWEN_32B_FAST = "Qwen/Qwen3-32B-fast"
LLAMA_8B_FAST = "Meta-Llama/Llama-3.1-8B-Instruct"

# SambaNova format (simple name):
SAMBANOVA_QWEN_32B = "Qwen3-32B"
SAMBANOVA_LLAMA_8B = "Meta-Llama-3.1-8B-Instruct"

# Metadata service format (enum values):
# Expects: "32B-fast", "480B", "72B", "7B-fast"
```

**Impact:**
- Need mapping functions like `map_model_to_metadata_enum()` in multiple places
- Provider-specific routing logic in LLM Gateway
- Fragile string matching patterns
- Hard to maintain as we add more providers

**Example Complexity:**
```python
# In main_ingestion_api.py:57-78
def map_model_to_metadata_enum(model_name: str) -> str:
    """
    Map full LLM model names to metadata service enum values.
    This function shouldn't even need to exist!
    """
    model_lower = model_name.lower()

    if "qwen3-32b" in model_lower or "qwen/qwen3-32b-fast" in model_lower:
        return "32B-fast"
    elif "480b" in model_lower:
        return "480B"
    # ... 20 more lines of string matching
```

### 3. No Hot-Reload Mechanism
**Impact:**
- Services import `model_registry` at startup and store values as module constants
- Changing configuration requires full service restart
- No dynamic configuration updates
- Slow iteration cycle during development/testing

### 4. Configuration Split Across Multiple Files
**Current Configuration Locations:**
1. `shared/model_registry.py` - Model definitions and defaults
2. `.env` - API keys + Model overrides (lines 109-110, 145-149)
3. Individual service config files - Service-specific settings
4. LLM Gateway routing logic - Provider detection
5. Mapping functions scattered across services

**Impact:**
- Hard to understand what model will actually be used
- Changes require editing multiple files
- High risk of inconsistencies

---

## Specific Examples of Complexity

### Example 1: Switching from Nebius to SambaNova (Current Process)

**Steps Required:**
1. Edit `.env` lines 145-149:
   ```bash
   LLM_MODEL_INTENT=Qwen3-32B                     # Change from Qwen/Qwen3-32B-fast
   LLM_MODEL_METADATA=Qwen3-32B                   # Change from Qwen/Qwen3-32B-fast
   # ... 5 more model variables
   ```

2. Kill and restart 5+ services:
   ```bash
   lsof -ti:8074 | xargs kill -9  # Answer Generation
   lsof -ti:8075 | xargs kill -9  # Intent Detection
   lsof -ti:8076 | xargs kill -9  # Compression
   lsof -ti:8062 | xargs kill -9  # Metadata
   lsof -ti:8065 | xargs kill -9  # LLM Gateway
   # Then restart all 5 services individually
   ```

3. Verify routing in LLM Gateway logs:
   ```bash
   tail -f /tmp/llm_gateway.log | grep ROUTING
   # Check that it shows "â†’ SambaNova API" not "â†’ Nebius API"
   ```

4. Test and debug when things break:
   - Some services still using old models (cache not cleared)
   - Model name format mismatches causing errors
   - Provider detection failing

**Time Required:** 15-30 minutes
**Error Potential:** HIGH

### Example 2: Metadata Service Model Name Mismatch

**What Happened:**
- Main Ingestion API sends: `"model": "Qwen3-32B"`
- Metadata service expects: `"model": "32B-fast"`
- Result: **422 Unprocessable Entity error**

**Fix Required:**
- Write a mapping function in `main_ingestion_api.py:57-78`
- Apply mapping at every call site (lines 442, 501)
- Maintain this mapping as providers/models change

**This is architectural complexity that shouldn't exist!**

---

## User's Critical Question

> "and where will our keys stay?"

### Answer: API Keys STAY in `.env` - This is Correct!

**Security Best Practice:**
```bash
# .env - ONLY for secrets and infrastructure configuration
NEBIUS_API_KEY=nbsk_xxxxxxxxxxxxxx
SAMBANOVA_API_KEY=your_sambanova_key_here
JINA_API_KEY=your_jina_key_here

# Infrastructure endpoints
NEBIUS_API_URL=https://api.studio.nebius.ai/v1
SAMBANOVA_API_URL=https://api.sambanova.ai/v1

# NOT for model selection - remove these:
# LLM_MODEL_INTENT=Qwen3-32B              # â† DELETE (move to model_registry.py)
# LLM_MODEL_METADATA=Qwen3-32B            # â† DELETE (move to model_registry.py)
# LLM_MODEL_ANSWER_SIMPLE=...             # â† DELETE (move to model_registry.py)
```

**Separation of Concerns:**
- `.env` = Secrets (API keys, credentials) + Infrastructure (URLs, ports)
- `model_registry.py` = Model selection and configuration
- Service config files = Service-specific behavior settings

---

## Proposed Solution

### Design Principle
**"Change one line in `model_registry.py`, everything updates automatically"**

### 1. Remove Model Overrides from `.env`

**Before (.env lines 145-149):**
```bash
LLM_MODEL_INTENT=Qwen3-32B
LLM_MODEL_ANSWER_SIMPLE=Meta-Llama-3.1-8B-Instruct
LLM_MODEL_ANSWER_COMPLEX=Qwen3-32B
LLM_MODEL_COMPRESSION=Qwen3-32B
LLM_MODEL_METADATA=Qwen3-32B
```

**After (.env - REMOVE these lines entirely):**
```bash
# Model selection moved to shared/model_registry.py
# Only secrets and infrastructure config remain here
```

### 2. Make `model_registry.py` the Single Source of Truth

**Add Provider Presets:**
```python
# shared/model_registry.py

class ProviderPreset:
    """Predefined provider configurations for easy switching"""

    NEBIUS_FAST = {
        "intent": LLMModels.QWEN_32B_FAST,           # Qwen/Qwen3-32B-fast
        "answer_simple": LLMModels.LLAMA_8B_FAST,    # Meta-Llama/Llama-3.1-8B-Instruct
        "answer_complex": LLMModels.QWEN_32B_FAST,   # Qwen/Qwen3-32B-fast
        "compression": LLMModels.QWEN_32B_FAST,
        "metadata": LLMModels.QWEN_32B_FAST,
    }

    SAMBANOVA_FAST = {
        "intent": LLMModels.SAMBANOVA_QWEN_32B,          # Qwen3-32B
        "answer_simple": LLMModels.SAMBANOVA_LLAMA_8B,   # Meta-Llama-3.1-8B-Instruct
        "answer_complex": LLMModels.SAMBANOVA_QWEN_32B,  # Qwen3-32B
        "compression": LLMModels.SAMBANOVA_QWEN_32B,
        "metadata": LLMModels.SAMBANOVA_QWEN_32B,
    }

    # Add more presets as needed (OPENAI, ANTHROPIC, etc.)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸŽ¯ CHANGE ONLY THIS LINE TO SWITCH PROVIDERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ACTIVE_PRESET = ProviderPreset.SAMBANOVA_FAST  # â† ONE LINE CHANGE!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Auto-populate defaults from active preset
DEFAULT_LLM_INTENT = ACTIVE_PRESET["intent"]
DEFAULT_LLM_ANSWER_SIMPLE = ACTIVE_PRESET["answer_simple"]
DEFAULT_LLM_ANSWER_COMPLEX = ACTIVE_PRESET["answer_complex"]
DEFAULT_LLM_COMPRESSION = ACTIVE_PRESET["compression"]
DEFAULT_LLM_METADATA = ACTIVE_PRESET["metadata"]
```

**Usage in Code:**
```python
from shared import DEFAULT_LLM_INTENT, DEFAULT_LLM_METADATA

# Services just use these - no .env reading, no mapping needed
model = DEFAULT_LLM_INTENT  # Always gets the right value from registry
```

### 3. Unify Model Naming with Metadata Layer

**Add Model Metadata in Registry:**
```python
class ModelInfo:
    """Complete model metadata including all naming formats"""

    def __init__(self, canonical_name: str, provider: str,
                 api_name: str = None, metadata_enum: str = None):
        self.canonical = canonical_name      # Internal reference name
        self.provider = provider              # "nebius", "sambanova", "jina"
        self.api_name = api_name or canonical_name  # Name for API calls
        self.metadata_enum = metadata_enum    # Metadata service enum

# Model definitions with full metadata
MODELS = {
    "qwen-32b-nebius": ModelInfo(
        canonical_name="qwen-32b-nebius",
        provider="nebius",
        api_name="Qwen/Qwen3-32B-fast",
        metadata_enum="32B-fast"
    ),
    "qwen-32b-sambanova": ModelInfo(
        canonical_name="qwen-32b-sambanova",
        provider="sambanova",
        api_name="Qwen3-32B",
        metadata_enum="32B-fast"
    ),
}

def get_model_info(model_name: str) -> ModelInfo:
    """Get complete model metadata - NO string matching needed!"""
    return MODELS.get(model_name)
```

**Eliminates Mapping Functions:**
```python
# Before (complex):
def map_model_to_metadata_enum(model_name: str) -> str:
    model_lower = model_name.lower()
    if "qwen3-32b" in model_lower or "qwen/qwen3-32b-fast" in model_lower:
        return "32B-fast"
    # ... 20 lines of string matching

# After (simple):
model_info = get_model_info(DEFAULT_LLM_METADATA)
metadata_enum = model_info.metadata_enum  # Direct lookup, no mapping!
```

### 4. Hot-Reload Configuration (Optional Enhancement)

**Add Configuration Watcher:**
```python
# shared/config_watcher.py

import time
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class ConfigReloader(FileSystemEventHandler):
    def __init__(self, reload_callback):
        self.reload_callback = reload_callback
        self.last_reload = time.time()

    def on_modified(self, event):
        if event.src_path.endswith("model_registry.py"):
            # Debounce: Only reload if > 2 seconds since last reload
            if time.time() - self.last_reload > 2:
                print("[CONFIG] model_registry.py changed - reloading...")
                self.reload_callback()
                self.last_reload = time.time()

def watch_config_changes(reload_callback):
    """Watch model_registry.py for changes and reload"""
    path = Path(__file__).parent / "model_registry.py"
    observer = Observer()
    observer.schedule(ConfigReloader(reload_callback), path.parent)
    observer.start()
    return observer
```

**Service Integration:**
```python
# In each service's startup
from shared.config_watcher import watch_config_changes

def reload_models():
    """Reload model configuration without restarting service"""
    importlib.reload(model_registry)
    global DEFAULT_LLM_INTENT
    DEFAULT_LLM_INTENT = model_registry.DEFAULT_LLM_INTENT
    print(f"[CONFIG] Reloaded: Intent model now {DEFAULT_LLM_INTENT}")

# Start watching for config changes
observer = watch_config_changes(reload_models)
```

**Result:** Change model_registry.py â†’ All services auto-reload within 2 seconds (no manual restarts!)

---

## Implementation Plan

### Phase 1: Cleanup (2 hours)
**Goal:** Remove `.env` model overrides, consolidate to registry

- [ ] **Task 1.1:** Remove model selection variables from `.env` (lines 145-149)
  - Keep API keys and infrastructure URLs
  - Document what was removed and why

- [ ] **Task 1.2:** Add `ProviderPreset` class to `model_registry.py`
  - Create presets for NEBIUS_FAST, SAMBANOVA_FAST
  - Add ACTIVE_PRESET selector

- [ ] **Task 1.3:** Update all services to use registry defaults
  - Remove `.env` reading for model selection
  - Import from `shared` instead

- [ ] **Task 1.4:** Test that services still work
  - Verify Ingestion pipeline
  - Verify Retrieval pipeline
  - Check all 5 LLM-dependent services

### Phase 2: Unify Model Naming (2-3 hours)
**Goal:** Eliminate model name format mapping functions

- [ ] **Task 2.1:** Create `ModelInfo` class with all name formats
  - canonical_name: Internal reference
  - api_name: For provider API calls
  - metadata_enum: For metadata service
  - provider: Provider identifier

- [ ] **Task 2.2:** Populate `MODELS` dictionary with metadata
  - Add all Nebius models
  - Add all SambaNova models
  - Add all Jina models

- [ ] **Task 2.3:** Replace mapping functions with lookups
  - Remove `map_model_to_metadata_enum()` from `main_ingestion_api.py:57-78`
  - Replace with `get_model_info(model).metadata_enum`
  - Update LLM Gateway provider detection

- [ ] **Task 2.4:** Test model routing
  - Verify Nebius API calls use correct format
  - Verify SambaNova API calls use correct format
  - Verify metadata service gets correct enum values

### Phase 3: Hot-Reload (Optional, 1-2 hours)
**Goal:** Enable configuration changes without service restarts

- [ ] **Task 3.1:** Create `config_watcher.py` module
  - File watcher for `model_registry.py` changes
  - Debounced reload mechanism

- [ ] **Task 3.2:** Integrate into services
  - Add reload hooks to FastAPI apps
  - Test configuration updates propagate

- [ ] **Task 3.3:** Add reload endpoint (optional)
  - `POST /admin/reload-config` endpoint
  - Manual trigger for config reload

### Phase 4: Documentation (1 hour)
**Goal:** Document the new simple workflow

- [ ] **Task 4.1:** Update README with new workflow
  - How to switch providers (change one line)
  - Where API keys go (.env)
  - Where model selection goes (model_registry.py)

- [ ] **Task 4.2:** Add inline documentation
  - Comment the ACTIVE_PRESET line clearly
  - Document ModelInfo structure

- [ ] **Task 4.3:** Create migration guide
  - For teams already using old .env approach
  - How to convert existing configurations

---

## Success Criteria

### After This Refactor:

âœ… **Switching providers takes < 30 seconds:**
1. Edit ONE line in `model_registry.py`: `ACTIVE_PRESET = ProviderPreset.SAMBANOVA_FAST`
2. (Optional) Restart services OR wait 2s for hot-reload
3. Done!

âœ… **No model name format mapping needed:**
- All formats stored in `ModelInfo` metadata
- Direct lookups replace string matching
- Add new models by adding to `MODELS` dict

âœ… **Clear separation of concerns:**
- `.env` = Secrets + Infrastructure
- `model_registry.py` = Model selection
- Service configs = Service behavior

âœ… **Easy to understand and maintain:**
- Single source of truth for models
- Obvious where to make changes
- Self-documenting with presets

âœ… **Developer experience improved:**
- Fast iteration cycle
- Low error potential
- Easy onboarding for new team members

---

## Testing Checklist

After implementing, verify:

- [ ] Switch `ACTIVE_PRESET` from Nebius to SambaNova
- [ ] Restart services (or verify hot-reload works)
- [ ] Run ingestion: `python test_ingestion.py`
  - Check metadata uses correct model
  - Verify no 422 errors (enum format correct)
  - Confirm 18 chunks ingested

- [ ] Run retrieval: `python rag_stage_tester.py --stage 5`
  - Check intent detection uses correct model
  - Check answer generation uses correct model
  - Verify LLM Gateway routes correctly

- [ ] Check LLM Gateway logs:
  ```bash
  tail -f /tmp/llm_gateway.log | grep ROUTING
  # Should show: "â†’ SambaNova API" for all requests
  ```

- [ ] Switch back to Nebius preset and verify still works

- [ ] Test with mixed preset (Nebius for some, SambaNova for others):
  ```python
  CUSTOM_PRESET = {
      "intent": LLMModels.SAMBANOVA_QWEN_32B,  # Fast intent with SambaNova
      "answer_complex": LLMModels.QWEN_CODER_480B,  # Complex with Nebius 480B
      "metadata": LLMModels.QWEN_32B_FAST,  # Metadata with Nebius
  }
  ACTIVE_PRESET = CUSTOM_PRESET
  ```

---

## Benefits Summary

### For Developers:
- **10x faster iteration:** Change one line vs 15-30 minute process
- **Lower cognitive load:** One place to look, clear what's active
- **Fewer errors:** No manual mapping, no service coordination issues

### For System:
- **Better maintainability:** Single source of truth
- **Easier scaling:** Add new providers by adding presets
- **Cleaner architecture:** Proper separation of concerns

### For Team:
- **Faster onboarding:** New developers see `ACTIVE_PRESET` and understand immediately
- **Better collaboration:** No conflicts from editing .env differently
- **Reduced debugging:** Fewer "why is this service using the wrong model?" questions

---

## Related Issues

This refactor addresses:
- User feedback: "why changing all these takes so long"
- Model name format inconsistencies across providers
- Service restart requirements for config changes
- Scattered configuration across multiple files
- Complex mapping functions that shouldn't exist

## References

- Current implementation: `shared/model_registry.py:1-672`
- Mapping function example: `main_ingestion_api.py:57-78`
- .env model overrides: `.env:145-149`
- Provider routing: `llm_gateway.py:336-350`

---

**Next Steps:** Prioritize this refactor in upcoming sprint. The current complexity is a barrier to rapid experimentation and testing, which is critical for RAG system optimization.
