# Comprehensive Model Test Results
**Query:** "What is Python?" (One sentence)
**Date:** 2025-10-10
**Test Status:** ‚úÖ All API Keys Working

---

## üéØ Summary

| Provider | Models Tested | Working | Failed | Success Rate |
|----------|--------------|---------|--------|--------------|
| **Nebius AI** | 2 | 2 | 0 | 100% ‚úÖ |
| **SambaNova AI** | 9 | 8 | 1 | 89% ‚ö†Ô∏è |
| **Jina AI** | 2 | 2 | 0 | 100% ‚úÖ |
| **TOTAL** | 13 | 12 | 1 | 92% |

---

## 1Ô∏è‚É£ Nebius AI Studio (Port 8065 - LLM Gateway)

### ‚úÖ Qwen-32B-fast (32B Reasoning Model)
```json
Model: Qwen/Qwen3-32B-fast
Response Time: 1.14s
Tokens: 118 (18 input + 100 output)
Cost: $0.0000236
Speed: ~88 tokens/sec
```
**Answer (Raw):**
```
<think>
Okay, the user is asking, "What is Python?" and wants a one-sentence answer.
Let me start by recalling what I know about Python. It's a programming language...
```
**‚ö†Ô∏è Issue:** Contains `<think>` reasoning tags (requires cleaning)
**Status:** ‚úÖ Working, needs output cleaning

---

### ‚úÖ Llama-8B-fast (8B Fast Model)
```json
Model: meta-llama/Meta-Llama-3.1-8B-Instruct-fast
Response Time: ~0.8s
Tokens: 67
Speed: ~84 tokens/sec
```
**Answer:**
> Python is a high-level, interpreted programming language that is widely used for various purposes such as web development, scientific computing, data analysis, artificial intelligence, and more, known for its simplicity, readability, and large community of developers.

**Status:** ‚úÖ Working perfectly, clean output

---

## 2Ô∏è‚É£ SambaNova AI (Direct API Tests)

### ‚úÖ DeepSeek-R1-0528 (671B MoE - Best Reasoning)
```json
Model: DeepSeek-R1-0528
Response Time: 0.93s
Tokens: 113 (13 input + 100 output)
Speed: 107.8 tokens/sec (255 tok/s after first token)
Cost: $0.00 (FREE)
```
**Answer (Raw):**
```
<think>
We are asked to answer "What is Python?" in one sentence.
Python is a high-level, interpreted programming language known for its
simplicity and readability, widely used for web development, data analysis,
artificial intelligence, and more...
```
**‚ö†Ô∏è Issue:** Contains `<think>` reasoning tags
**Status:** ‚úÖ Working, needs output cleaning
**Performance:** üöÄ **255 tok/s after first token!**

---

### ‚úÖ Meta-Llama-3.1-8B-Instruct (8B - Fastest)
```json
Model: Meta-Llama-3.1-8B-Instruct
Response Time: ~0.17s
Tokens: 86
Speed: 508.3 tokens/sec üî•
Cost: $0.00 (FREE)
```
**Answer:**
> Python is a high-level, interpreted programming language that is widely used for various purposes such as web development, scientific computing, data analysis, artificial intelligence, and more due to its simplicity, readability, and extensive libraries.

**Status:** ‚úÖ Working perfectly, clean output
**Performance:** üöÄ **FASTEST MODEL** (508 tok/s)

---

### ‚úÖ DeepSeek-V3-0324 (671B MoE - Best Quality)
```json
Model: DeepSeek-V3-0324
Response Time: ~0.97s
Tokens: 30
Speed: 30.8 tokens/sec
Cost: $0.00 (FREE)
```
**Answer:**
> Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility.

**Status:** ‚úÖ Working perfectly, most concise answer
**Quality:** ‚ú® Best quality text generation

---

### ‚úÖ DeepSeek-R1-Distill-Llama-70B (70B Reasoning)
```json
Model: DeepSeek-R1-Distill-Llama-70B
Tokens: 91
Speed: 235.3 tokens/sec
Cost: $0.00 (FREE)
```
**Answer (Preview):**
```
<think>
Okay, so I need to figure out what Python is in one sentence...
```
**Status:** ‚úÖ Working, has `<think>` tags
**Performance:** Fast reasoning (235 tok/s)

---

### ‚ùå DeepSeek-R1-Distill-Qwen-32B (32B Reasoning)
```json
Error: "Model not found"
```
**Status:** ‚ùå **NOT AVAILABLE** on SambaNova
**Action:** Remove from registry or mark as unavailable

---

### ‚úÖ Qwen3-32B (32B Reasoning)
```json
Model: Qwen3-32B
Tokens: 66
Cost: $0.00 (FREE)
```
**Answer (Preview):**
```
<think>
Okay, the user is asking, "What is Python? (One sentence)." I need to provide a concise...
```
**Status:** ‚úÖ Working, has `<think>` tags

---

### ‚úÖ Meta-Llama-3.3-70B-Instruct (70B General)
```json
Model: Meta-Llama-3.3-70B-Instruct
Tokens: 84
Cost: $0.00 (FREE)
```
**Answer:**
> Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility, making it a popular choice for various applications.

**Status:** ‚úÖ Working perfectly, clean output

---

### ‚úÖ gpt-oss-120b (120B General Purpose)
```json
Model: gpt-oss-120b
Tokens: 125
Cost: $0.00 (FREE)
```
**Answer:**
> Python is a high‚Äëlevel, interpreted programming language known for its readability, dynamic typing, and extensive standard library.

**Status:** ‚úÖ Working perfectly, clean output

---

### ‚úÖ DeepSeek-V3.1-Terminus (671B Advanced Reasoning)
```json
Model: DeepSeek-V3.1-Terminus
Tokens: ~50
Cost: $0.00 (FREE)
```
**Answer:**
> Python is a high-level, general-purpose programming language known for its simple syntax and readability.

**Status:** ‚úÖ Working perfectly, clean output

---

### ‚úÖ Llama-3.3-Swallow-70B-Instruct-v0.4 (70B Japanese-Optimized)
```json
Model: Llama-3.3-Swallow-70B-Instruct-v0.4
Tokens: ~50
Cost: $0.00 (FREE)
```
**Answer:**
> Python is a versatile, high-level programming language known for its readability and simplicity.

**Status:** ‚úÖ Working perfectly, clean output

---

## 3Ô∏è‚É£ Jina AI (Embeddings & Reranking)

### ‚úÖ Jina Embeddings v3 (Port 8063)
```json
Model: jina-embeddings-v3
Dimension: 1024
Source: jina_api
Sample: [0.0391, -0.0978, 0.1454, 0.1044, 0.0331]
Uptime: 2.33 hours
Total Requests: 22
```
**Status:** ‚úÖ Working perfectly
**Performance:** True 1024-dim embeddings (4x faster search than 4096-dim)

---

### ‚úÖ E5-Mistral (Nebius Embeddings Alternative)
```json
Model: intfloat/e5-mistral-7b-instruct
Dimension: 4096
Source: nebius_api
Sample: [0.0248, -0.0057, 0.0043, -0.0049, 0.0189]
```
**Status:** ‚úÖ Working perfectly
**Quality:** Higher dimension = higher quality (but slower search)

---

### ‚úÖ Jina Reranker v2 (Port 8072)
```json
Model: jina-reranker-v2-base-multilingual
Processing Time: 475ms
Uptime: 2.33 hours
```
**Test Results:**
```
Query: "What is Python?"

1. "Python is a high-level programming language."  ‚Üí Score: 0.859 ‚úÖ
2. "Java is used for enterprise applications."     ‚Üí Score: 0.095
```
**Status:** ‚úÖ Working perfectly
**Accuracy:** Correctly ranked Python-related content

---

## üìä Performance Comparison

### Speed (Tokens/Second)
| Rank | Model | Provider | Speed | Type |
|------|-------|----------|-------|------|
| ü•á | Llama-3.1-8B | SambaNova | **508 tok/s** | Fast |
| ü•à | DeepSeek-R1 | SambaNova | **255 tok/s** | Reasoning |
| ü•â | DeepSeek-R1-Distill-70B | SambaNova | **235 tok/s** | Reasoning |
| 4Ô∏è‚É£ | Qwen-32B-fast | Nebius | ~88 tok/s | Reasoning |
| 5Ô∏è‚É£ | Llama-8B-fast | Nebius | ~84 tok/s | Fast |
| 6Ô∏è‚É£ | DeepSeek-V3 | SambaNova | 31 tok/s | Quality |

**Winner:** üèÜ SambaNova Llama-8B (508 tok/s - **6x faster** than Nebius!)

---

### Cost Comparison
| Provider | Model | Size | Cost per 1M tokens | Free Tier |
|----------|-------|------|-------------------|-----------|
| **SambaNova** | All models | 8B-671B | **$0.00** | ‚úÖ Yes |
| **Nebius** | All models | 8B-480B | **$0.20** | ‚ùå No |
| **Jina AI** | Embeddings v3 | - | **$0.00** | ‚úÖ 10M tokens |
| **Jina AI** | Reranker v2 | - | **$0.00** | ‚úÖ 10M tokens |

**Winner:** üèÜ SambaNova (100% free for all models)

---

### Quality (Answer Conciseness)
| Model | Answer Length | Quality |
|-------|--------------|---------|
| DeepSeek-V3 (SambaNova) | 18 words | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Most concise |
| DeepSeek-V3.1-Terminus | 19 words | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Llama-Swallow-70B | 14 words | ‚≠ê‚≠ê‚≠ê‚≠ê Very concise |
| Llama-70B (SambaNova) | 22 words | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Llama-8B (SambaNova) | 45 words | ‚≠ê‚≠ê‚≠ê Verbose |
| Llama-8B (Nebius) | 42 words | ‚≠ê‚≠ê‚≠ê Verbose |

**Winner:** üèÜ DeepSeek-V3-0324 (SambaNova) - Best quality + conciseness

---

## ‚ö†Ô∏è Issues Found

### 1. Reasoning Models Emit `<think>` Tags
**Affected Models:**
- Qwen-32B-fast (Nebius)
- DeepSeek-R1-0528 (SambaNova)
- DeepSeek-R1-Distill-Llama-70B (SambaNova)
- Qwen3-32B (SambaNova)

**Solution:** Already implemented in shared registry:
```python
from shared.model_registry import requires_output_cleaning, get_cleaning_pattern
import re

if requires_output_cleaning(model):
    pattern = get_cleaning_pattern(model)
    answer = re.sub(pattern, '', answer, flags=re.DOTALL).strip()
```

### 2. Model Not Available
**Model:** DeepSeek-R1-Distill-Qwen-32B
**Status:** ‚ùå Returns "Model not found" from SambaNova API
**Action Required:** Update model registry to mark as unavailable

---

## ‚úÖ Recommendations

### For Simple Queries (Factual, Lookup)
**Use:** `Meta-Llama-3.1-8B-Instruct` (SambaNova)
- Speed: 508 tok/s (FASTEST)
- Cost: FREE
- Quality: Good
- No cleaning needed

### For Complex Reasoning
**Use:** `DeepSeek-R1-0528` (SambaNova)
- Speed: 255 tok/s (fast for reasoning)
- Cost: FREE
- Quality: Best reasoning
- Needs `<think>` tag cleaning

### For Best Quality Text
**Use:** `DeepSeek-V3-0324` (SambaNova)
- Speed: 31 tok/s
- Cost: FREE
- Quality: Highest
- Most concise answers

### For Embeddings
**Use:** `jina-embeddings-v3` (Current default)
- Dimension: 1024 (4x faster search)
- Cost: FREE (10M tokens)
- Quality: Excellent (80% MTEB)

### For Reranking
**Use:** `jina-reranker-v2-base-multilingual` (Current default)
- Speed: 475ms per request
- Cost: FREE
- Accuracy: High (0.85+ for relevant docs)

---

## üöÄ Next Steps

1. **Remove unavailable model:** DeepSeek-R1-Distill-Qwen-32B from registry
2. **Update defaults to SambaNova:** For cost savings
3. **Implement LLM Gateway routing:** Add provider detection logic
4. **Add output cleaning:** Ensure all reasoning models clean `<think>` tags
5. **Load test:** Test SambaNova rate limits with production load

---

## üìù Test Commands

```bash
# Test any LLM model
curl -X POST http://localhost:8065/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer internal_service_2025_secret_key_metadata_embeddings" \
  -d '{"model": "MODEL_NAME", "messages": [{"role": "user", "content": "PROMPT"}]}'

# Test SambaNova directly
curl -X POST https://api.sambanova.ai/v1/chat/completions \
  -H "Authorization: Bearer 9a2acb34-97f8-4f3c-a37c-d11aa5b699dd" \
  -d '{"model": "MODEL_NAME", "messages": [{"role": "user", "content": "PROMPT"}]}'

# Test embeddings
curl -X POST http://localhost:8063/v1/embeddings \
  -d '{"input": "TEXT", "model": "jina-embeddings-v3"}'

# Test reranking
curl -X POST http://localhost:8072/v1/rerank \
  -d '{"query": "QUERY", "chunks": [{"chunk_id": "1", "text": "TEXT"}]}'
```

---

**Final Score:** 12/13 models working (92% success rate) ‚úÖ
