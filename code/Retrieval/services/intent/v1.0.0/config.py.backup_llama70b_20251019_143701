#!/usr/bin/env python3
"""
Configuration for Intent & Prompt Adaptation Service v1.0.0
Query intent detection and prompt template selection
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Load common .env from PipeLineServices root
# Path hierarchy: config.py → v1.0.0 → intent → services → Retrieval → PipeLineServices
PIPELINE_ROOT = Path(__file__).resolve().parents[4]  # PipeLineServices directory
env_path = PIPELINE_ROOT / ".env"
load_dotenv(env_path)

# Add shared directory to path for model registry
SHARED_DIR = PIPELINE_ROOT / "shared"
sys.path.insert(0, str(SHARED_DIR))

from model_registry import get_llm_for_task, LLMModels

# Service metadata
API_VERSION = "1.0.0"
SERVICE_NAME = "Intent & Prompt Adaptation Service"
SERVICE_DESCRIPTION = "Query intent detection and prompt template selection for RAG pipeline"

# Server config
DEFAULT_HOST = os.getenv("HOST", "0.0.0.0")
DEFAULT_PORT = int(os.getenv("INTENT_SERVICE_PORT", "8075"))

# Dependent service URLs
# Note: Use base URL without endpoint path (intent_api.py adds /health for health checks and /v1/chat/completions for API calls)
LLM_GATEWAY_URL = os.getenv("LLM_GATEWAY_URL_DEVELOPMENT", "http://localhost:8065").replace("/v1/chat/completions", "")

# LLM parameters for intent detection
# Use central model registry for intent detection model
INTENT_DETECTION_MODEL = get_llm_for_task("intent_detection")  # Uses Qwen-32B-fast by default
INTENT_MAX_TOKENS = int(os.getenv("INTENT_MAX_TOKENS", "1024"))  # Increased for full JSON response with reasoning
INTENT_TEMPERATURE = float(os.getenv("INTENT_TEMPERATURE", "0.1"))  # Low for consistent classification

# Performance settings
REQUEST_TIMEOUT = int(os.getenv("REQUEST_TIMEOUT", "30"))  # seconds
ENABLE_CACHE = False  # Intent detection is fast, no caching needed

# Intent confidence thresholds
CONFIDENCE_THRESHOLD_REJECT = float(os.getenv("CONFIDENCE_THRESHOLD_REJECT", "0.40"))  # Below this: reject request
CONFIDENCE_THRESHOLD_FALLBACK = float(os.getenv("CONFIDENCE_THRESHOLD_FALLBACK", "0.60"))  # Below this: use fallback intent
# Above FALLBACK threshold: use detected intent normally

# Logging configuration
LOG_DIR = Path(__file__).resolve().parent / "logs"
LOG_DIR.mkdir(exist_ok=True)
LOW_CONFIDENCE_LOG_FILE = LOG_DIR / "low_confidence_queries.jsonl"  # JSON Lines format
REJECTED_QUERIES_LOG_FILE = LOG_DIR / "rejected_queries.jsonl"
LOG_RETENTION_DAYS = int(os.getenv("LOG_RETENTION_DAYS", "7"))  # Keep logs for 7 days

# Supported intent types (15-intent comprehensive taxonomy)
SUPPORTED_INTENTS = [
    # GROUP 1: Core Retrieval (5)
    "simple_lookup",
    "list_enumeration",
    "yes_no",
    "definition_explanation",
    "factual_retrieval",
    # GROUP 2: Analytical (5)
    "comparison",
    "aggregation",
    "temporal",
    "relationship_mapping",
    "contextual_explanation",
    # GROUP 3: Advanced Logic (3)
    "negative_logic",
    "cross_reference",
    "synthesis",
    # GROUP 4: Meta/Structural (2)
    "document_navigation",
    "exception_handling"
]

# Supported languages (ISO 639-1 codes)
SUPPORTED_LANGUAGES = ["en", "es", "fr", "de", "it", "pt", "ja", "zh", "ko", "ar", "hi"]

# ============================================================================
# Dynamic Model Recommendation for Answer Generation
# ============================================================================
def recommend_answer_model(intent: str) -> str:
    """
    Recommend which LLM model Answer Generation should use based on intent complexity

    Simple intents (fast model - Llama-8B-fast):
    - simple_lookup, yes_no, list_enumeration
    - comparison (most comparisons are straightforward)
    - definition_explanation, factual_retrieval
    - document_navigation

    Complex intents (reasoning model - Qwen-32B-fast):
    - cross_reference (systematic comparison across sets)
    - synthesis (multi-source integration)
    - negative_logic (NOT/absence detection)
    - relationship_mapping (entity relationships)
    - aggregation (mathematical operations)
    - temporal (date arithmetic)
    - contextual_explanation (deep "why" reasoning)
    - exception_handling (policy violations)

    Args:
        intent: Detected intent type

    Returns:
        Model ID (full model name)
    """
    # Complex intents that need strong reasoning (32B model)
    complex_intents = {
        "cross_reference",      # Needs systematic comparison across sets
        "synthesis",            # Needs multi-source integration and analysis
        "negative_logic",       # Needs NOT/absence detection logic
        "relationship_mapping", # Needs entity relationship graph understanding
        "aggregation",          # Needs mathematical operations and calculations
        "temporal",             # Needs date arithmetic and timeline reasoning
        "contextual_explanation", # Needs deep reasoning about "why" questions
        "exception_handling"    # Needs understanding of policy violations
    }

    if intent in complex_intents:
        return get_llm_for_task("answer_generation", complexity="complex", intent=intent)
    else:
        return get_llm_for_task("answer_generation", complexity="simple", intent=intent)

def recommend_max_tokens(intent: str) -> int:
    """
    Recommend max_tokens for answer generation based on intent type

    Token allocation strategy:
    - Short answers (512 tokens): yes_no, simple_lookup
    - Medium answers (1024 tokens): definition, factual_retrieval, document_navigation, temporal, exception_handling
    - Long answers (2048 tokens): aggregation, synthesis, comparison, cross_reference, negative_logic
    - Very long answers (3072 tokens): list_enumeration (comprehensive lists)

    Args:
        intent: Detected intent type

    Returns:
        Recommended max_tokens value
    """
    # Very long answers - comprehensive lists or detailed enumerations
    if intent in ["list_enumeration"]:
        return 3072

    # Long answers - detailed analysis, specifications, multi-source synthesis
    if intent in [
        "aggregation",          # Needs to list multiple items with specs (e.g., highest-priced product with full technical specifications)
        "synthesis",            # Needs to integrate multiple sources comprehensively
        "comparison",           # Needs side-by-side detailed comparison with technical details
        "cross_reference",      # Needs comprehensive cross-document analysis with context
        "contextual_explanation", # Needs deep explanatory content with examples
        "relationship_mapping",  # Needs detailed relationship descriptions across entities
        "negative_logic"        # Needs room for <think> reasoning tags + actual filtered results (increased from 1024 to 2048)
    ]:
        return 2048

    # Medium answers - standard factual responses
    if intent in [
        "definition_explanation",
        "factual_retrieval",
        "document_navigation",
        "temporal",
        "exception_handling"
    ]:
        return 1024

    # Short answers - yes/no, simple lookups
    if intent in ["yes_no", "simple_lookup"]:
        return 512

    # Default fallback for any unknown intents
    return 1536

def recommend_response_style(intent: str) -> str:
    """
    Recommend default response style based on intent type (Hybrid Approach)

    Style allocation strategy:
    - Concise (2-4 bullet points): simple_lookup, yes_no, negative_logic, list_enumeration (simple lists)
    - Balanced (organized, moderate detail): comparison, factual_retrieval, definition_explanation, temporal, document_navigation
    - Comprehensive (full analysis with tables/sections): aggregation, synthesis, cross_reference, relationship_mapping, contextual_explanation, exception_handling

    Args:
        intent: Detected intent type

    Returns:
        Recommended response_style ("concise", "balanced", or "comprehensive")
    """
    # Concise answers - direct, minimal formatting
    if intent in ["simple_lookup", "yes_no", "negative_logic"]:
        return "concise"

    # Balanced answers - organized but not excessive
    if intent in [
        "comparison",           # Side-by-side comparison without excessive tables
        "factual_retrieval",    # Organized facts without too much detail
        "definition_explanation", # Clear explanations without verbosity
        "temporal",             # Chronological info without excessive formatting
        "document_navigation",  # Simple location guidance
        "list_enumeration"      # Simple lists without elaborate descriptions
    ]:
        return "balanced"

    # Comprehensive answers - full analysis with rich formatting
    if intent in [
        "aggregation",          # Needs detailed calculations, specs, and breakdowns
        "synthesis",            # Needs multi-source integration with full context
        "cross_reference",      # Needs comprehensive cross-document analysis
        "relationship_mapping", # Needs detailed relationship diagrams and explanations
        "contextual_explanation", # Needs deep reasoning with examples
        "exception_handling"    # Needs thorough policy/compliance analysis
    ]:
        return "comprehensive"

    # Default fallback for unknown intents
    return "balanced"
